## 实验一：MLP

- 数据预处理：按编号将被试人员的数据分组读入，共读入十二组数据，每组数据的62*5维数据直接摊平为310维的数据，因此每个被试的数据是`num*310`维
- 为了实现跨被试留一，将每个被试的数据都进行编号，在训练和测试时利用`LeaveOneGroupOut`实现跨被试留一测试
- 模型结构：采用简单MLP，共四层，层分别为`(310,256),(256,128),(128,64),(64,32),(32,16)`，每层之间均采用`ReLU`作为激活函数，最后的输出层维度为32维，采用`Softmax`函数将输出转换为概率分布，从而实现多分类的目标
- 超参设置：由于该模型较小，我们可以采用网格搜索来寻找最合适的超参
- `'learning_rate': [0.1, 0.01, 0.001]`
- ` 'hidden_layer_sizes': [[256, 128, 64, 32],[128, 64, 32],[64, 32]],` 
- `'activation_function': [nn.ReLU, nn.Tanh, nn.LeakyReLU],` 
- ` 'optimizer': ['Adam', 'SGD'],` 
- `'num_epochs': [100, 250, 500]`
- 最终的超参组合是：`lr:0.001,layer:[256,128,64,32],activation:nn.ReLU,optimizer:Adam,epoch:250`
- 最终结果：